


- [VainF/Torch-Pruning: A pytorch pruning toolkit for structured neural network pruning and layer dependency maintaining.](https://github.com/VainF/Torch-Pruning)  
摘要：This tool will automatically detect and handle layer dependencies (channel consistency) during pruning. It is able to handle various network architectures such as DenseNet, ResNet, and Inception. See examples/test_models.py for more supported models.  
- [sovrasov/flops-counter.pytorch: Flops counter for convolutional networks in pytorch framework](https://github.com/sovrasov/flops-counter.pytorch)  
摘要：This script is designed to compute the theoretical amount of multiply-add operations in convolutional neural networks. It also can compute the number of parameters and print per-layer computational cost of a given network.  
Supported layers: Conv1d/2d/3d (including grouping), ConvTranspose1d/2d/3d (including grouping), BatchNorm1d/2d/3d, Activations (ReLU, PReLU, ELU, ReLU6, LeakyReLU), Linear, Upsample
Poolings (AvgPool1d/2d/3d, MaxPool1d/2d/3d and adaptive ones).  
Experimental support: RNN, LSTM, GRU (NLH layout is assumed), RNNCell, LSTMCell, GRUCell.  
- [tencent-ailab/pika: a lightweight speech processing toolkit based on Pytorch and (Py)Kaldi](https://github.com/tencent-ailab/pika)  
摘要：PIKA is a lightweight speech processing toolkit based on Pytorch and (Py)Kaldi. The first release focuses on end-to-end speech recognition. We use Pytorch as deep learning engine, Kaldi for data formatting and feature extraction.  
Key Features: 1. On-the-fly data augmentation and feature extraction loader; 2. TDNN Transformer encoder and convolution and transformer based decoder model structure; 3. RNNT training and batch decoding; 4. RNNT decoding with external Ngram FSTs (on-the-fly rescoring, aka, shallow fusion); 5. RNNT Minimum Bayes Risk (MBR) training; 6. LAS forward and backward rescorer for RNNT; 7. Efficient BMUF (Block model update filtering) based distributed training.  
