---
layout: default
---

# 嵌入式AI简报 (2020-11-30)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本次19条。


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 华为：新机将首发天玑700，入门级5G SoC，7nm工艺，8核CPU，2xA76@2.2GHz+6xA55@2.0GHz，集成Mail-G57 MC2 GPU，支持双模5G；  
- 华为：官宣出售荣耀。分拆的根本矛盾是华为芯片受到制约。华为打算在两年之内，实现20nm芯片的自主制造和量产，为此需千亿级别的投入，收购方是华为30多家合作伙伴成立的深圳市智信新信息技术有限公司，收购价2633亿。根据网络爆料，分拆后荣耀将三年内上市，原属于华为的Nova和畅想系列也会归入荣耀；  
- 联发科：将通过旗下子公司立锜并购Intel旗下Enpirion电源管理芯片产品线相关资产，预计交易金额约8500万美元，最快今年第四季度完成交易。原产品线针对FPGA芯片、车用处理器，以及低功耗平台的高集成度电源管理模块；  
- 联发科：除了双11推出入门级5G SoC 天玑700外，预告一款6nm制程，基于A78新架构的MT6893Z/CZA，3GHz主频、Mali-G77MC9 GPU方案，面向大众消费者的普及型高端平台；  
- 台积电：2nm工艺突破，有望2023年下半年风险性试产，2024年步入量产。2nm上，台积电将放弃延续多年的FinFET(鳍式场效应晶体管)，甚至不用三星在3nm工艺上使用的GAAFET，也就是纳米线，而将其拓展成为“MBCFET“；  
- 苹果：2021年iPhone中的A15芯片将坚持使用5nm工艺，但会转向台积电称为“5nm+/N5P”的性能增强版。目前iPhone 12是使用台积电5nm制程的手机；  
- AMD：宣布350亿美元收购赛灵思，CPU、GPU、FPGA全凑齐，AMD希望借赛灵思的FPGA和SmartNIC等产品进一步占据数据中心市场；  
- 英伟达：发布2021财年第三季度财务报告，截至2020年10月25日第三季度收入创下47.3亿美元的纪录，较去年同期的30.1亿美元增长57%，较上一季度的38.7亿美元增长22%；  
- 平头哥：Sipeed（矽速科技）发布基于平头哥「玄铁C906」的Sipeed MaixCube开发板，「玄铁C906」是一款高能效、RV64兼容处理器，针对算术运算、内存访问等方面进行了增强，同时标配内存管理单元，可运行Linux操作系统。配有单/双精度浮点引擎，可进一步选配面向AI加速的向量计算引擎，适用于视频监控、人工智能等应用领域。  

> 注：个别链接打不开，请点击文末【阅读原文】跳转

## 业界新闻  


- [微软小冰：拿下首轮投资，开始「成年冒险」 | 极客公园](https://mp.weixin.qq.com/s/WxpjgXt7DJQ89QLHhM1HRA)  
摘要：今年 5 月，小冰科技有限公司注册成立。7 月中旬，小冰正式从微软拆分，成为一家独立运营的公司。沈向洋担任新公司董事长，李笛担任 CEO。新公司将继续保留中国小冰、日本 Rinna 品牌。至此，小冰脱离微软大体系，告别微软羽翼的庇护，从温室走向丛林。  
小冰从文本到多模态交互，覆盖、融合了 AI 人工智能领域几乎所有主流技术。支撑起全球超 60% 的 AI 交互总量，交互总量稳居全球第一。仅小冰单一品牌就覆盖了 6.6 亿在线用户、4.5 亿台第三方智能设备、9 亿内容用户。  
目前，小冰联合微软特别针对金融、智能汽车、内容生产三个领域场景推出行业解决方案。  
- [苹果：自研M1芯片登场，或将再次颠覆PC行业 | 三易生活](https://mp.weixin.qq.com/s/bBI95NbnG1GZOHjMCPkbiw)  
摘要：M1集成了“四大四小”的八个CPU核心，它们全都基于ARM指令集，但由苹果自行设计基础架构。并且值得一提的是，M1在CPU缓存的设计上表现得非常“慷慨”，比如说它的四枚性能核心共拥有192KB指令缓存、128KB数据缓存，以及12MB的共享二级缓存，这就相当于每一枚大核各自拥有48KB指令缓存、32KB数据缓存和3MB的二级缓存。而作为对比，当下PC领域的消费级旗舰处理器Intel Core i9-10900K，每个核心的缓存配置仅仅只有32KB指令、32KB数据、256KB二级缓存，以及2MB三级缓存。  
GPU部分其实也有着不少的看点。据悉，它同样基于苹果自研的图形处理器技术，采用了八核心的并行设计，并且共拥有128个执行单元。而值得注意的是，“执行单元”并不等于目前市场上PC端GPU的“流处理器”，毕竟一个执行单元内部是可能包含多个流处理器，因此在这一点上苹果与Intel的计算方式其实要更相似一些。它的像素填充率和纹理填充率分别是41GP/s和82GT/s，再加上高达2.6TFlops的浮点性能，这意味着M1的GPU性能超过了AMD锐龙4000系APU里的Vega8（1.792TFlops）和Intel十一代酷睿里的Xe 96EU核显（2.074TFlops），几乎已经达到了NVIDIA GeForce GTX1650Ti移动标压版（像素填充43.2GP/s、纹理填充86.4GT/s，浮点性能2.765TFlops）的水准。然而GeForce GTX1650Ti移动标压版是一款TDP高达55W的GPU，而M1的苹果自研图形处理器方案，则仅仅只是这款芯片内部的一小块“集显”而已。  

- [快手：手机端分分钟拥有哈利波特的隐身衣 | 量子位](https://mp.weixin.qq.com/s/b69D_aYT9eKx0lD61T66Jw)  
摘要：要把画面中的人抹掉，除了自动把人像抠出来之外，AI还得学会脑补人像遮挡住的真实背景。这就涉及到两方面的问题：初始帧人像区域的背景修复，以及后续相机、人物运动过程中人像区域的背景填充。为了解决这两个问题，算法整体分成了两个阶段：首帧使用移动端脑补模型实现对人像区域的背景填充，后续帧使用帧间实时跟踪匹配投影，实现可见背景区域向人物遮挡区域的填充。其中用到了基于开源的DeepFill图像修复算法。  
性能方面，则是使用自研的YCNN深度学习推理引擎。拿CPU来说，无论是苹果、高通、华为还是联发科的芯片，无论是高端的骁龙865还是低端的骁龙450、430，YCNN引擎都能支持模型在上面运行。同样，GPU方面，YCNN引擎同时支持Mali、Adreno、Apple和英伟达等多种GPU。NPU方面，苹果Bionic，华为HiAI，高通SNPE和MTK的APU均在支持范围之内。  

- [AMD推出Matrix Core，对标英伟达Tensor Core | 机器之心](https://mp.weixin.qq.com/s/__oWqRq8OtjETQECJIvWjQ)  
摘要：为对标英伟达 Tensor core，一直发展迅猛的 AMD 也推出了类似功能单元 Matrix Core。同时，基于 Matrix Core 技术，AMD 发布了新型 AMD Instinct MI100 加速器，据称是全球最快的 HPC GPU 和首个超越 10 teraflops (FP64) 性能的 x86 服务器 GPU。
AMD Instinct MI100 GPU 配备了全新 AMD CDNA 架构，使用第二代 AMD EPYC 处理器，面向 HPC 和 AI。性能上，MI100 为 HPC 提供了高达 11.5 TFLOPS 的 FP64 峰值性能，为 AI 和机器学习提供了高达 46.1 TFLOPS 的 FP32 Matrix 峰值性能。与其上一代加速器相比，MI100 凭借新的 AMD Matrix Core 技术，为 AI 训练提供了近 7 倍的 FP16 理论峰值浮点性能提升。  
AMD 还推出了 ROCm 4.0。ROCm 开发者软件平台旨在为百亿亿级计算提供基础，包括编译器、编程 API 和库。此次推出的 ROCm 4.0 针对基于 MI100 的系统进行了优化，将编译器升级为开源版本，并支持 OpenMP 5.0 和 HIP。经过 ROCm 4.0 优化，PyTorch 和 Tensorflow 框架可以基于 MI100 实现更高的性能。  
- [tensorflow/tensorflow: 为新旧Mac特供新版本，GPU可用于训练，速度最高提升7倍 | 机器之心](https://mp.weixin.qq.com/s/hgVeOjs07y0rEu4gM9RNuw)  
摘要：TensorFlow 2.4 框架针对 Mac 版做了优化，M1 版 Mac 和英特尔版 Mac 都能用。其 tensorflow_macos 分支用到了苹果的 ML Compute，能让 GPU 也被利用起来。苹果在其博客中介绍说：「通过使用更高级别的优化方法如层融合，选择合适设备类型，将图作为原语编译，由 CPU 上的 BNNS 和 GPU 上的 Metal Performance Shader 加速。」  
M1 芯片将苹果的神经网络引擎引入了 Mac，实现了 15 倍的机器学习任务加速。该神经网络引擎有 16 个核心，每秒运算速度可达 11 万亿次。此外，配置了 ML 加速器的 CPU 和 GPU（称霸集显，媲美部分独显）也使得整个 M1 芯片的机器学习能力得到巨大提升。Mac 版 TensorFlow 2.4 的详细入门指南可以参见：https://github.com/apple/tensorflow_macos 。  


## 论文


- [2011.12289v1] [MicroNet: 计算量低到极致的图像识别模型](https://arxiv.org/abs/2011.12289v1)  
标题：[MicroNet: Towards Image Recognition with Extremely Low FLOPs](https://arxiv.org/abs/2011.12289v1)  
摘要：作者提出MicroNet，如在ImageNet分类上仅有6MFLOPs。然而，低计算量通常意味着低精度，因此做了两项改进（a）通过降低节点连接性来避免网络宽度的减少；（b）通过每层引入更复杂的非线性来补偿网络深度的减少。  
首先，作者提出微因子卷积，将点向卷积和深向卷积分解为低秩矩阵，以便在信道数量和输入/输出连通性之间平衡。其次，提出一种新的激活函数Dynamic Shift Max，通过最大化输入特征映射与其循环通道偏移之间的多个动态融合，来改善非线性。基于这两个工作，MicroNet在低计算量下实现了比现有技术更显著的性能增益。例如，MicroNet-M1以12个MFLOPs在ImageNet分类中达到61.1%的最高精度，比MobileNetV3高出11.3%。  
- [2010.10499] [Bort：BERT轻量化，找到最优参数子集，大小仅为BERT-large的16% | 量子位](https://mp.weixin.qq.com/s/RlCAKi1UtRIiT8EYrpjUQA)  
标题：[Optimal Subarchitecture Extraction For BERT](https://arxiv.org/abs/2010.10499)  
代码：https://github.com/alexa/bort  
摘要：亚马逊Alexa团队对BERT模型进行参数选择，通过完全多项式时间近似算法（FPTAS）优化改问题，其中列举了三个指标：推理速度，参数大小和错误率，获得了BERT的最优参数子集——Bort，其大小仅为BERT-large的16％，但是在CPU上的速度却快了7.9倍，在NLU基准测试上的性能也优于BERT-large。   
- [2011.04233] [基于Transformer的车道线检测算法：420 fps，又快又好](https://mp.weixin.qq.com/s/V2xmoUvzn8Ikvvf6BuZw-g)  
标题：[End-to-end Lane Shape Prediction with Transformers](https://arxiv.org/abs/2011.04233)  
摘要：该文为车道线检测问题建立参数模型，使用Transformer捕获道路中细长车道线特征和全局特征，所发明的车道线检测算法与以往相比，可端到端训练、参数量更少、速度更快（高达420 fps，单1080Ti）。  
车道线检测以往的方法往往需要经过特征提取和后处理两个过程，这使得整个算法不能端到端训练，作者借助于对车道线曲线和相机内参的描述，采用多项式参数模型来描述车道线，并配以Bipartite Matching Loss函数，实现端到端训练，网络的目标成为预测几个参数，这无需后处理且降低了计算量。  
- [NIPS2020] [MiniLM：通用模型压缩方法 | 小窗幽记机器学习](https://mp.weixin.qq.com/s/iLO1FOE-4z1p07RCfCJIaA)  
标题：[iniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers](https://arxiv.org/abs/2002.10957)  
代码：https://github.com/microsoft/unilm/tree/master/minilm  
摘要：预训练模型过大的话，有2个弊端：推理速度慢，内存空间占用大。为解决该问题，作者提出了一种通用的面向Transformer-based预训练模型压缩方法：MiniLM。  
MiniLM有3个核心点：1. 蒸馏teacher模型最后一层Transformer的自注意力模块；2. 在自注意模块中引入值之间的点积；3. 引入助教模型辅助模型蒸馏。  
实验表明，各种参数尺寸的student模型中，MiniLM的单语种模型优于各种最先进的蒸馏方案。在 SQuAD 2.0和GLUE的多个任务上以一半的参数和计算量就保持住99%的accuracy。此外，MiniLM在多语种预训练模型上也取得不错的结果。  
- [2009.04323] [VoiceFilter-Lite：谷歌发布新一代定向人声分离系统，2.2MB模型提升设备端语音识别 | 机器之心](https://mp.weixin.qq.com/s/hOfdyUH4AhUA1rmkZprVIQ)  
标题：[VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device Speech Recognition](https://arxiv.org/abs/2009.04323)  
博客：https://ai.googleblog.com/2020/11/improving-on-device-speech-recognition.html  
摘要：2018 年，谷歌科学家王泉等人发表 VoiceFilter 系统，利用声纹识别实现定向人声分离。最近，王泉等人挑战设备端语音识别难题，提出新一代定向人声分离系统 VoiceFilter-Lite，只需 2.2MB 大小的模型，就能将重叠语音的词错率（word error rate）降低 25.1%。  
该模型能够用于设备端语音识别，从而让用户在没有网络连接的情况下，也能在嘈杂的背景噪声环境下使用语音助手。人声分离算法被用于语音识别时，一个常见的问题是过度抑制（over-suppression），也就是将本应保留的部分有用信号错误地过滤掉，导致识别出的文本缺失大量字词。由于最近的语音识别模型普遍采用大量数据增强方法，所以过度抑制造成的问题远大于抑制不足（under-suppression）。  
VoiceFilter-Lite 在设计过程中采用了两种方法来解决过度抑制的问题。首先，在训练过程中，损失函数采用了非对称的形式，也就是过度抑制相比抑制不足会有更大的权重。此外，模型被设计为可以动态检测重叠语音的存在。当检测到输入信号包含重叠语音时，模型将采用更大的抑制强度。  


## 开源项目


> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [tensorflow/tensorflow: 2.4.0 候选版本发布 | TensorFlow](https://mp.weixin.qq.com/s/Mf4N_F5xRUuB0VklK7wjLg)  
摘要：这里仅说一下TFLite方面的主要特性，TFLite Profiler Android 版本现已推出，tf.lite引入quantization.quantize_and_dequantize_v2，可以更新超过范围的量化的梯度定义，更多信息参考：https://github.com/tensorflow/tensorflow/releases/tag/v2.4.0-rc0 ；  
- [OAID/AutoKernel: 一个简单易用，低门槛的自动算子优化工具，提高深度学习算法部署效率](https://github.com/OAID/AutoKernel)  
摘要：AutoKernel是由OPEN AI LAB提出的高性能算子自动优化工具，可以自动优化调度策略、生成底层优化代码，大幅减少各硬件芯片算子开发成本，提升算子优化效率，让工程师更快实现深度学习算法在各硬件芯片上的高性能部署。AutoKernel特色：低门槛、简单易用、高效率。AutoKernel分为三个模块：算子生成器，自动搜索模块，以及算子部署插件。  
算子生成器：该模块使用了开源项目Halide；Halide是业界广泛使用的自动代码生成项目，它首次提出将计算和调度分离。该模块的输入是和硬件无关的算子计算描述，输出是相应后端的优化汇编代码/目标文件；  
自动搜索模块：该模块可以通过最优化算法/搜索算法/机器学习/强化学习搜索出相应后端的最优算子的调度策略参数（该模块仍在开发中）；  
算子部署插件（ AutoKernel Plugin）：Tengine是OPEN AILAB开源的深度学习推理框架，实现了AI算法在不同硬件的快速高效部署。该模块实现了将自动生成的优化算子代码以plugin的形式一键集成到Tengine中，实现自动优化算子的一键部署。  
- [RangiLyu/nanodet: NanoDet轻量级（1.8MB）、超快速（移动端97fps）目标检测项目 | OpenCV中文网](https://mp.weixin.qq.com/s/KC-QxYZf2471OICDFra7Zw)  
代码：https://github.com/RangiLyu/nanodet/
摘要：目标检测模型NanoDet特点如下：超轻量级：模型文件只有1.8 MB；超快速：在移动 ARM CPU 上达到 97fps(10.23ms)；训练友好：训练占用内存少。可设置Batch-size=80，在 GTX1060 6G上也可以训练；易部署：作者提供了基于 ncnn 推理的 C++ 实现和安卓部署 demo。  
- [bytedance/lightseq: 字节跳动开源序列推理引擎LightSeq，速度超快！ | 机器之心](https://mp.weixin.qq.com/s/HUSYSrjG65p1TU9lS_KEUA)  
摘要：lightseq 对以 Transformer 为基础的序列特征提取器（Encoder）和自回归的序列解码器（Decoder）做了深度优化，早在 2019 年 12 月就已经开源，应用在了包括火山翻译等众多业务和场景。据了解，这应该是业界第一款完整支持 Transformer、GPT 等多种模型高速推理的开源引擎。LightSeq 可以应用于机器翻译、自动问答、智能写作、对话回复生成等众多文本生成场景，大大提高线上模型推理速度，改善用户的使用体验，降低企业的运营服务成本。相比于目前其他开源序列推理引擎，LightSeq具有如下几点优势：  
1.高性能：LightSeq推理速度非常快。例如在翻译任务上，LightSeq相比于Tensorflow实现最多可以达到14倍的加速。同时领先目前其他开源序列推理引擎，例如最多可比Faster Transformer快1.4倍；  
2.支持模型功能多：LightSeq支持BERT、GPT、Transformer、VAE 等众多模型，同时支持beam search、diverse beam search、sampling等多种解码方式；  
3.简单易用，无缝衔接Tensorflow、PyTorch等深度学习框架：LightSeq通过定义模型协议，支持各种深度学习框架训练好的模型灵活导入。同时包含了开箱即用的端到端模型服务，即在不需要写一行代码的情况下部署高速模型推理，同时也灵活支持多层次复用。  


## 博文


- [深度学习框架如何进行性能优化 | OneFlow](https://mp.weixin.qq.com/s/wOb7LjPKuRGNBt1dW34r7A)  
摘要：OneFlow v0.2.0发布后，除了框架的易用性和完备性的提升在有序推进以外，最主要的更新就是多达17个性能优化，使得CNN和BERT的自动混合精度（AMP，Auto   Mixed  Precision）训练速度大幅提升，不仅远超其他各个主要框架的官方实现，同时也超过了NVIDIA深度优化过的版本，在主流旗舰显卡（V100   16G）上训练ResNet50-v1.5和BERT-base模型有着 “王者”表现。OneFlow ResNet50-v1.5 AMP单卡比NVIDIA深度优化过的国际知名框架A快80%，比国际知名框架B快35%。  
- [基于JS语言的DL框架——7个浏览器深度学习框架调研：还有很长的路要走 | 机器之心](https://mp.weixin.qq.com/s/C7QdVathJ8YTXF-zXPC-Ow)  
摘要：作者基于WWW’19 论文提供的线索，详细解读了在浏览器中实现深度学习的可能性、可行性和性能现状。具体而言，作者重点分析了 7 个最近出现的基于JavaScript 的 DL 框架，并对比了具体框架支持哪些 DL 任务。其中包括：TensorFlow.js、ConvNetJS、Keras.js、WebDNN、brain.js、synaptic、Mind。除性能外，作者还比较了模型大小，支持的GPU后端数量，模型体积大小等。  
- [快手：将GPU推理在广告推荐商业化场景全量落地，机器成本优化超20% | 机器之心](https://mp.weixin.qq.com/s/m7I9BguNWp5dGgOde5-yGA)  
摘要：对于推荐、广告等场景使用的大规模稀疏模型，业内一般用 TensorFlow 训练，GPU 场景推理选择 TensorFlow 或 TensorRT。对于 TensorFlow 和 TensorRT 的结合，常见的做法是将 TensorFlow 模型转到 ONNX 模型，然后从 ONNX 模型加载，这限制了模型的结构，也导致训练好的 TensorFlow 模型无法直接以端到端的形式应用于线上。   
快手借鉴业界经验，从实际业务出发，围绕大规模稀疏模型场景，针对发挥 GPU 算力和 TensorFlow 与 TensorRT 的结合易用性，进行了一系列技术上的探索和尝试。  
首先是计算流水优化，提升硬件利用率，利用多 cuda stream，同时运行多个 Compute Engine，增加 GPU 有效工作时间的占比，使每个 Compute Engine 对应两条 Cuda stream，优化了 H2D 数据传输到 GPU 计算的流水，自动对 TF graph 做裁剪，减少重复计算和内存拷贝，不断优化 CPU 到 GPU 的流水（比如对 user 侧 embedding 在卡上展开），达到算力均衡。此外，快手也结合场景和模型的特点，快手也进行了针对性的设计和优化，结合 CPU 和 GPU 的优势，保证大规模模型的线上应用。  
- [LLVM中的pass及其管理机制 | 知乎](https://zhuanlan.zhihu.com/p/290946850)  
摘要：LLVM编译器框架的核心概念是任务调度和执行。编译器开发者将IR分解为不同的处理对象，并将其处理过程实现为单独的pass类型。在编译器初始化时，pass被实例化，并被添加到pass管理器中。pass管理器以流水线的方式将各个独立的pass衔接起来，然后以预定义顺序遍历每个pass，根据pass实例返回值启动、停止或重复运行不同pass。因此，LLVM pass管理机制的主要模块包括pass、pass管理器、pass注册及相关模块，如PassRegistry、AnalysisUsage、AnalysisResolver等。本文将会介绍这其中的Pass和相关机制。  
- [工程师如何在工作中提升自己 | 美团技术团队](https://mp.weixin.qq.com/s/DwDzOcQZIK9vd6FQTyuIWQ)  
摘要：如何在繁忙的工作中做好技术积累，构建个人核心竞争力，相信是很多工程师同行都在思考的问题。本文作者试图从三个方面来解答：  
第一部分，阐述了一些学习的原则。任何时候，遵循一些经过检验的原则，都是影响效率的重要因素，正确的方法是成功的秘诀。提升工作和学习效率的另一个重要因素是释惑和良好心态。第二部分分析了我在工作中碰到和看到的一些典型困惑。成为优秀的架构师是大部分初中级工程师的阶段性目标。第三部分剖析架构师的能力模型，让大家对目标所需能力有一个比较清晰的认知。  


> 注：个别链接打不开，请点击文末【阅读原文】跳转


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
|  |  | [2020-10-21](../embedded-ai-report/2020-10-21.md) | [2020-09-17](../embedded-ai-report/2020-09-17.md) |
| [2020-08-26](../embedded-ai-report/2020-08-26.md) | [2020-08-06](../embedded-ai-report/2020-08-06.md) | [2020-07-18](../embedded-ai-report/2020-07-18.md) | [2020-07-02](../embedded-ai-report/2020-07-02.md) |
| [2020-06-17](../embedded-ai-report/2020-06-17.md) | [2020-06-03](../embedded-ai-report/2020-06-03.md)  | [2020-05-15](../embedded-ai-report/2020-05-15.md) | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
