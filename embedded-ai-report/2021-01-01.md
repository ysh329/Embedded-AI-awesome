---
layout: default
---

# 嵌入式AI简报 (2021-01-01) <标题><标题><标题><标题><标题><标题><标题><标题><标题>

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本次21条。【新闻】苹果自研ARM架构M1登场，Imagination发布新AI加速器IP IMG Series4 NNA，AMD推出Matrix Core对标英伟达Tensor Core，TensorFlow Mac深度优化版可训练；【论文】性能精度双超MBV3且仅有6MFLOPs的MicorNet，BERT压缩之大小仅为BERT-large的16%的Bort，基于Transformer 420FPS的车道线检测算法，面向Transformer-based通用模型压缩方法MiniLM，谷歌2.2MB的新版人声分离端侧模型VoiceFilter-Lite；【开源】TensorFlow 2.4.0 候选版本发布，OPEN AI Lab开源简单易用的自动算子优化工具AutoKernel，移动端cpu 97fps模型仅1.8MB的NanoDet目标检测模型，字节跳动开源序列推理引擎LightSeq；【博文】深度学习框架如何进行性能优化，7个基于JS的浏览器深度学习框架调研，快手在广告推荐场景的GPU推理实践，苹果 Vision 官方框架（基于Core ML）使用入门。


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 华为：新机将首发天玑700，入门级支持双模5G SoC，7nm，2xA76@2.2GHz+6xA55@2.0GHz，Mail-G57 MC2 GPU；  
- 华为：官宣出售荣耀。并打算实现20nm芯片的自主制造和量产，为此需千亿级别的投入；
- 联发科：将通过旗下子公司立锜并购Intel旗下Enpirion电源管理芯片产品线，原产品线针对FPGA、车用低功耗平台等的电源管理模块；  
- 联发科：预告一款6nm制程普及型高端平台SoC，基于A78新架构的MT6893Z/CZA，3GHz主频、Mali-G77MC9 GPU方案；  
- 台积电：3nm工厂竣工：2022年苹果A16处理器首发量产；2nm工艺突破，有望2023年下半年试产，2024年步入量产；  
- 苹果：2021年iPhone中的A15芯片将坚持使用5nm工艺，转向“5nm+/N5P”的性能增强版。目前iPhone 12是使用台积电5nm制程；  
- AMD：拟350亿美元收购赛灵思，CPU、GPU、FPGA全凑齐，希望借赛灵思的FPGA和SmartNIC进一步占据数据中心市场；  
- 英伟达：财报截至2020年10月25日第三季度收入创下47.3亿美元的纪录，较去年同期30.1亿美元增长57%，较上一季度的38.7亿美元增长22%；  
- 小冰：脱离微软体系，拿下首轮投资，联合微软特别针对金融、智能汽车、内容生产三个领域场景推出行业解决方案。  

----

- 地平线：计划 C 轮融资总额超 7 亿美金，已完成 C1 轮融资。本轮融资将主要用于加速地平线车载人工智能芯片和智能驾驶解决方案的研发和商业化进程；  
- 云从：冲刺科创板IPO！3年营收15.77亿净亏23亿，中科大校友创办，国有背景股东醒目；以人机协同操作系统为核心，通过「云-边-端」一体设备，赋能到智慧金融、智慧治理、智慧出行、智慧商业等应用场景；

> 注：个别链接打不开，请点击文末【阅读原文】跳转

## 业界新闻  

- [取代安培！NV下一代GPU曝光：终于5nm | 硬件世界](https://mp.weixin.qq.com/s/tYvjQh2grWfm6MZK1HZQyg)  
摘要： 图灵（Turing）和安培（Ampere）之后，很早就有爆料NVIDIA的下一代GPU将以“Hopper（赫柏）”知名，Hopper被誉为编译之母，是伟大的女性程序员。  
不过，爆料好手kopite7kimi意外透露，Hopper似乎被NVIDIA延后了，接替Ampere的另有其人。
具体来说，NVIDIA正规划的5nm GPU，将以“Ada Lovelace”为名，资料显示，她是诗人拜伦唯一合法的女儿，被誉为第一位计算机科学家、编写了历史上第一个计算机程序。  
传言Hopper采用的是MCM多芯设计，可能是复杂度更高，但也有一种可能是，Hopper会用于专业级、企业级产品，Ada Lovelace是消费级游戏类产品。  
- [谷歌发布 MediaPipe Holistic，实现移动端同时进行人脸、手部和人体关键点检测跟踪 | 新智元](https://mp.weixin.qq.com/s/0mmDhQmO7IuiQwVvz9fvEQ)  
  摘要：谷歌MediaPipe Holistic为突破性的 540 多个关键点（33 个姿势、21 个手和468 个人脸关键点）提供了统一的拓扑结构，并在移动设备上实现了近乎实时的性能。  
  在移动设备上对人体姿势、人脸关键点和手部追踪的实时同步感知，可以实现各种有趣的应用，如健身和运动分析、手势控制和手语识别、增强现实效果等。  
  谷歌之前发布的 MediaPipe 就是一个专门为GPU或CPU而设计的开源框架，已经为这些单个任务提供了快速、准确而又独立的解决方案。  
  开源地址：
  https://github.com/google/mediapipe
  原文链接：
  https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html
  演示地址：
  https://mediapipe.dev/demo/holistic_remote/



## 论文


- [伯克利人工智能实验室提出HAWQ: 基于Hessian矩阵的全自动混合精度量化方法 | 将门创投](https://mp.weixin.qq.com/s/9zGCr7s9zPxMBvcScJUOaA)  
代码：https://github.com/Zhen-Dong/HAWQ  
文章：https://papers.nips.cc/paper/2020/file/d77c703536718b95308130ff2e5cf9ee-Paper.pdf  
视频：https://neurips.cc/virtual/2020/protected/poster_d77c703536718b95308130ff2e5cf9ee.html  
摘要：混合精度量化 (Mixed-Precision Quantization) 是模型压缩领域的重要方法。HAWQ (音同Hawk，鹰) 提出了一种基于Hessian矩阵的可以全自动确定混合精度的方法。其核心思想是使用敏感度分析，对神经网络中特别敏感的层使用高量化位宽，对不敏感的层使用低量化位宽。  
本文是伯克利人工智能实验室 (BAIR) 发表于NeurIPS 2020的一项工作，提出Hessian矩阵的迹是衡量敏感程度的重要指标，并且基于此进行了组合优化。HAWQ的方法在不同模型和不同任务上泛化很好，取得了SOTA的量化结果(ImageNet Top1：8MB ResNet50 75.9%，1MB SqueezeNext 68.7%) 。  




## 开源项目


- [Jittor/jittor：清华「计图」迎来重大更新：支持热门的可微渲染，多项CV任务速度超越PyTorch]
Jittor项目地址：
https://github.com/


关注前沿科技  量子位

- [OpenCV/OpenCV：新版 4.5.1 发布 | OpenCV中文网](https://mp.weixin.qq.com/s/SgI01RzNxskzTcSmY3xGhw)  
项目地址：www.opencv.org  
摘要：1.集成更多的GSoC 2020 项目的结果，包括：开发了OpenCV.js DNN 模块，以方便再网页中使用，并提供了相关教程。目标检测/分类/风格迁移/语义分割等；
2. OpenCV.js WASM SIMD 优化 2.0，网页端调用OpenCV更快；
3. 新增文本检测和识别高级API；
4. SIFT算法优化，主要是16位整型高斯滤波指令加速
5. DNN模块的改进：1. 改进层/激活函数支持更多模型：1D卷积，1D池化；2. 修复Resize, ReduceMean，多输出收集，导入Faster RCNN ONNX模型；3. 支持INT32 ONNX张量；4. 英特尔®推理引擎后端（OpenVINO™）；5.增加了对OpenVINO 2021.2版本的支持，添加了对HDDL的预览支持。



## 博文

- [微信AI设计了一种超分辨率技术，让扫二维码更方便 | 微信AI](https://mp.weixin.qq.com/s/ZEthIoGsIm1KsHheWUviZg)  
摘要：对于微信扫码识别中分辨率低、小分辨率低质量的码图像，综合考虑性能与效率，设计了适用于移动端的超分算法，在保证速度的同时提高了扫码算法的识别成功率。经过一系列的精心设计，最终模型量化后体积仅有13K。在困难验证集上的实验测试中，与普通的bicubic插值相比，超分算法的将识别率由39.69%提高到了60.31%，在iPhone7上真机单帧耗时6.39ms（100x100），完全可以满足移动端的需求。  
- [YolactEdge:边缘设备上的实时实例分割(Xavier: 30 FPS | AI人工智能初学者](https://mp.weixin.qq.com/s/d32juNEVouPRXgPz03bTMg)  
摘要：YolactEdge是一个带有ResNet-101的网络，在550x550分辨率的图像上，其在Jetson AGX Xavier上的速度高达30.8 FPS，在RTX 2080 Ti上的速度为172.7 FPS，AP性能超强！速度是目前主流方法的3-5倍，代码刚刚开源！
作者对基于图像的最新实时方法YOLACT进行了两项改进：1. 优化TensorRT，同时谨慎权衡速度和准确性；2.利用视频中时间冗余的新型特征扭曲模块。  
在YouTube VIS和MS COCO数据集上进行的实验表明，与现有的实时方法相比，YolactEdge的速度提高了3-5倍，同时具有极好的mask和box检测精度。  
- [DeepMind力荐的JAX到底有多强大 | 将门创投](https://mp.weixin.qq.com/s/SBOOGgclAYBw7F0lmtyxjA)  
摘要：随着越来越多项目的使用，由谷歌研究开发的 JAX 工具包逐渐得到研究和工程领域人员的喜爱。JAX 是一个用于高性能数值计算的 Python 库，特别为机器学习领域的高性能计算设计。它的 API 基于 Numpy 构建，包含丰富的数值计算与科学计算函数。  
JAX 工具包具有良好的工程哲学和便捷的使用方法，DeepMind 的研究人员在充分地使用后整理出了详细的分析，并汇总了JAX的整个生态系统介绍，为想要入坑的小伙伴们提供了详细的参考。  
- [PyTorch 多机多卡训练：分布式数据并行（DDP）实战与技巧 | 极市平台](https://mp.weixin.qq.com/s/2E455tFiCqq2BVdt0BfkIA)  
摘要：DistributedDataParallel（DDP）是一个支持多机多卡、分布式训练的深度学习工程方法。其能达到略低于卡数的加速比,是目前最流行的多机多卡训练方法。在这篇文章里，作者通过几个实例，给大家介绍了DDP在实际生产中的应用，如在DDP中引入SyncBN,多机多卡环境下的inference加速等。  
本文作者将通过几个实战例子，来给大家介绍一下DDP在实际生产中的应用。内容包括：1.在DDP中引入SyncBN、2.DDP下的Gradient Accumulation的进一步加速、3.多机多卡环境下的inference加速、4.保证DDP性能：确保数据的一致性、5.和DDP有关的小技巧、6.控制不同进程的执行顺序、7.避免DDP带来的冗余输出。  
- [App 启动提速实践和一些想法 |  starming](https://mp.weixin.qq.com/s/v2Ym9GPU4J8xCFFNYcpJhg)  
摘要：启动是门面，好的印象也助于留存率提高。苹果也在系统启动上不断努力，提升用户体验，最新的 M1 宣传中还特别强调了翻盖秒开 macOS，可以看出其对极致启动速度的追求。这篇文章(https://farfetchtechblog.com/en/blog/post/mobile-app-launch-performance-ii/)提到，据 Akamai (https://wemakewebsites.com/blog/improve-page-load-speed-increase-conversion/)调查，每多1秒等待，转化率会下降7%，KissMetrics 的一份报告说启动超5秒，会使19%的用户放弃等待卸载 App。  
高德 App 启动优化专项完成后已经有一段时间了，一直保持实属不易，之前在这篇文章(https://ming1016.github.io/2019/12/07/how-to-analyze-startup-time-cost-in-ios/)里也做了些总结。本文将会再补充些启动优化用到一些手段和一些想法。  
