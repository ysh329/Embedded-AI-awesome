---
layout: default
---

# 嵌入式AI简报 (2021-07-15)：


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：


> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  

- [通用智能芯片设计公司“壁仞科技”首款7nm GPU芯片预计今年三季度流片，明年正式发布。
壁仞科技CTO兼首席架构师洪洲(Mike Hong)上周在接受媒体采访时表示，公司首款支持AI训练和推理的7nm芯片进展顺利，预计今年将正式流片。
洪洲表示，其性能将与 NVIDIA 的下一代 GPU 相媲美。

- [抢先体验NVIDIA DOCA，走在技术前沿 | NVIDIA英伟达](https://mp.weixin.qq.com/s/AFyVF6sIzWMJHmVeRaGwQw)  
摘要：CPU 用于通用计算，GPU 用于加速计算，DPU 则进行数据处理。CPU、GPU、DPU 正在成为未来计算的三大支柱。  
NVIDIA BlueField DPU是一种新型可编程处理器，专注于数据处理，能够满足企业对性能、安全性、可管理等越来越高的需求，它具有高性能及软件可编程的多核CPU、高性能网络接口、灵活且可编程的加速引擎。为了加速数据中心的部署、支持广大开发者在BlueField DPU进行软件开发，NVIDIA还为DPU量身打造了一个软件开发套件 —— DOCA。  




## 论文

- [华为诺亚加法网络再升级：精度提升，可以逼近任意函数 | 机器之心](https://mp.weixin.qq.com/s/LzcGFlEwzMiSf-BEYIOFjg)  
摘要：深度卷积神经网络的计算常常需要巨大的能耗，因此难以在移动设备上实现。为此学界正在探索研究各式各样的新方法，本文要介绍的这项研究提出了使用加法替代 CNN 中的乘法（卷积），从而极大降低神经网络使用时的能耗。
众所周知，乘法的速度慢于加法，但是深度神经网络前向推理过程中的计算包含了大量权重和激活函数之间的乘法。因此，许多论文尝试研究了如何减少神经网络中的乘法计算，从而加快深度学习速度。  
在这一方向上的开创性研究是 Yoshua Bengio 团队 2015 年提出的 BinaryConnect，其会将网络权重强制设为二值（比如 -1 或 1，这个过程称为二值化），使得卷积网络中的乘加运算可被简单的累加运算替代。在那之后，该团队进一步提出了二值化神经网络（Binarized neural networks，BNN），其不仅会将权重变为二值，而且也会将卷积神经网络运行时的激活也设为二值。 
而在 AdderNet 中，特征往往聚集在不同的类别中心，这是因为 AdderNet 使用了 L1 距离来区别不同的类别。这个可视化结果说明 L1 距离和传统的互相关都可被用作度量，来计算深度神经网络中滤波器与输入特征之间距离的相似度。由于减法可使用加法的补码轻松实现，因此仅使用加法的 L1 度量可作为一种对硬件友好的度量，并且在构建神经网络时可以很自然地有效替代卷积。 
该研究的初步结果已在 CVPR 2020 发表（arXiv:1912.13200）。本文要介绍的是最新的研究成果，在新版本中，AdderNet 的性能已经获得了显著的提升，并且还具有了完善的理论保证。  
在图像分类任务上，AdderNet 的表现与 CNN 相近，且几乎不需要任何乘法计算，在精度上优于二值化神经网络（BNN，不过 BNN 的模型要小得多）。在常用的 ResNet-18 和 ResNet-50 架构上，AdderNet 新版本的精度已经和原始卷积网络十分相似，差距在一个点以内。  


## 开源项目


> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。



## 博文


- [『豪门盛宴』AI训练芯片和系统最新战况 | StarryHeavensAbove](https://mp.weixin.qq.com/s/jVEY3PFeFymyKCL0oz6D8A)  
摘要：MLPerf的工作已经持续了几年，Training的Benchmark是最早开展工作，也是到目前为止最受瞩目的工作。不出意料的话，各个厂商都会“宣称”自己夺得了“xxx的冠军”。0.7版本的结果出来之后，Nvidia做了一个对比图，试图做归一化的比较，但也很难说是非常合理的对比。我之前对这个问题的比喻是“关公战秦琼”，这也是MLPerf基准测试面临的困难之一。
那么，如果结果很难对比的话，组织和参与这样的“竞赛”的意义是什么呢？  
第一，这符合“AI训练军备竞赛”的需要。只要在AI上“大力出奇迹”的规律不变，AI模型的规模就会越来越大。  
第二，有利于提升芯片厂商的综合能力。如前面MLPerf的简单介绍，它测试的是软硬件系统的综合能力。如果我们观察华为ResNet的数据，0.7版本使用Tensoflow框架，这次使用的是Mindspore。  
第三，Benchmark的设计和讨论本身也可以促进相关技术的进步。设计一个好的Benchmark也是高技术工作，需要对算法和系统软硬件的技术趋势和实现有深入的理解。  


