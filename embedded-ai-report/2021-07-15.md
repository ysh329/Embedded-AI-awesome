---
layout: default
---

# 嵌入式AI简报 (2021-07-15)：


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 高通：受不了三星制程性能太差，骁龙895+ 或将采用台积电 4 纳米，移动处理器大厂高通（Qualcomm） 预计在2022 年底推出的骁龙Snapdragon 895+ 移动处理将会采用苹果A16 Bionic 处理器相同的台积电4 纳米制程来进行生产；
- 格林深瞳：科创板IPO获上交所受理，本次拟募资10亿元。较之「AI四小龙」，这些营收数字并不算出色，格灵深瞳已然不在第一阵营，2B生意让收入起来了，但是现金回不来，政府生意不好做。也反映了目前中国的AI公司还没有强到可以打破既定行业规则；


> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  

- [通用智能芯片设计公司“壁仞科技”首款7nm GPU芯片预计今年三季度流片，明年正式发布](https://mp.weixin.qq.com/s/nblHuDI8AXxjp__o4w46HA)
壁仞科技CTO兼首席架构师洪洲(Mike Hong)上周在接受媒体采访时表示，公司首款支持AI训练和推理的7nm芯片进展顺利，预计今年将正式流片。
洪洲表示，其性能将与 NVIDIA 的下一代 GPU 相媲美。壁仞科技的第一款GPU芯片定位高端通用智能计算，具备高性能、可扩展性、可虚拟化等特性，支持云端训练和推理，目前已经到了收尾阶段，预计将在今年流片。
这颗芯片对标的，是国际GPU霸主英伟达还在酝酿之中的下一代5nm GPU计算芯片。
当然，一家初创公司如果刚起步就全面对标英伟达，无异于以卵击石。对此壁仞科技的策略是，先聚焦几个点上，打一场“不对称的战争”。英伟达GPU并非面向AI训练和推理的最优芯片，而是一个多能力芯片。以A100为例，其双精度对HPC很重要，但对AI加速来说，其在能效比、算力等方面并非最优解。因此壁仞科技选择首先专攻通用AI训练和推理能力，将图形渲染等与AI加速无关的设计剥离掉，更聚焦于在自家芯片上如何合理安排更多的运算和存储单元。  
等芯片流片后，壁仞科技下一步将重点推进加速芯片商用落地的软件工作。壁仞科技的第二款芯片已经开始启动架构设计，之后壁仞科技还将逐步推出面向智算中心、云游戏、边缘计算的GPU芯片。  
壁仞科技着重优化其芯片的3个亮点特性：通用性、高算力、芯粒（chiplet）技术。
1、通用性：从兼容CUDA到取代CUDA。新的GPU板卡要无缝地支持CUDA生态，这比更高的算力，更好的能效比更重要。壁仞科技的终极目标，是提供比CUDA更好的自研编程模型。  
2、高算力：融合多种架构的优点。以通用性为根本的同时，在专用领域做深耕、优化，融入多种架构的优点。不拘泥于传统的向量流处理架构，而会在其理念中加入数据流处理单元、近存储计算架构等其他元素，并对重点场景进行特殊优化，使其能处理各种数据类型，从而在同等能耗上，获得比英伟达高好几倍的算力。单颗芯片算力的提升只是一个点，壁仞科技还在其芯片中引入非常高的互连带宽，能做到数百数千的芯片大规模拓展，从而实现集群化大算力。  
3、芯粒（chiplet）：提高性价比的必备技术。  
截至目前，团队已扩张至超400人。壁仞科技将持续吸纳国内人才、招募海外人才、培养新鲜血液。
- [抢先体验NVIDIA DOCA，走在技术前沿 | NVIDIA英伟达](https://mp.weixin.qq.com/s/AFyVF6sIzWMJHmVeRaGwQw)  
摘要：CPU 用于通用计算，GPU 用于加速计算，DPU 则进行数据处理。CPU、GPU、DPU 正在成为未来计算的三大支柱。  
NVIDIA BlueField DPU是一种新型可编程处理器，专注于数据处理，能够满足企业对性能、安全性、可管理等越来越高的需求，它具有高性能及软件可编程的多核CPU、高性能网络接口、灵活且可编程的加速引擎。为了加速数据中心的部署、支持广大开发者在BlueField DPU进行软件开发，NVIDIA还为DPU量身打造了一个软件开发套件 —— DOCA。  
- [三星新旗舰Exynos 2200性能前瞻：AMD GPU神助攻 | 电脑爱好者](https://mp.weixin.qq.com/s/_A4sOoioaWBR6xxGh4GdYw)  
摘要：高通明年初量产的骁龙898（或骁龙895），将采用ARMv9指令集定制Cortex-X2、Cortex-A710、Cortex-510架构魔改而来的Kryo 780核心，并集成Adreno 730以及全新的DSP和ISP单元，整体性能将有巨大的提升。  
那么，骁龙898能否保持Android顶级SoC一哥的地位？有关三星下一代旗舰级SoC——Exynos 2200，三星准备了四款样片，其中2款采用Cortex-X1做超大核，1款采用最新的Cortex-X2做超大核，还有1款保守的型号则采用Cortex-A78。作为消费者，我们自然是希望Exynos 2200可以直接用上Cortex-X2+Cortex-A710+Cortex-510这种纯ARMv9架构打造的CPU矩阵。  
和其他竞品相比，三星Exynos 2200最大的特色，就是集成了来自AMD授权定制的RDNA 2架构GPU。前不久网上还传出了一张三星Exynos处理器运行3DMark Wild Life基准测试的成绩图，截图显示，带有AMD Radeon GPU和Cortex-A77 CPU的Exynos芯片组得分8134分，平均帧率为50FPS。  
从Cortex-A77 CPU架构来看，Exynos处理器应该属于还半成品，主要就是用于验证AMD Radeon GPU的可靠性与实力。当这颗GPU与Cortex-X2为代表的ARMv9架构核心搭配时，理论上可以释放出更强悍的性能。作为对比，高通骁龙888和麒麟9000的3DMark Wild Life基准测试跑分分别为5720和6677，由此可见AMD Radeon GPU的性能还是非常给力的，反正肯定是不会输给高通下一代的Adreno 730 GPU。  


## 论文

- [华为诺亚加法网络再升级：精度提升，可以逼近任意函数 | 机器之心](https://mp.weixin.qq.com/s/LzcGFlEwzMiSf-BEYIOFjg)  
摘要：深度卷积神经网络的计算常常需要巨大的能耗，因此难以在移动设备上实现。为此学界正在探索研究各式各样的新方法，本文要介绍的这项研究提出了使用加法替代 CNN 中的乘法（卷积），从而极大降低神经网络使用时的能耗。
众所周知，乘法的速度慢于加法，但是深度神经网络前向推理过程中的计算包含了大量权重和激活函数之间的乘法。因此，许多论文尝试研究了如何减少神经网络中的乘法计算，从而加快深度学习速度。  
在这一方向上的开创性研究是 Yoshua Bengio 团队 2015 年提出的 BinaryConnect，其会将网络权重强制设为二值（比如 -1 或 1，这个过程称为二值化），使得卷积网络中的乘加运算可被简单的累加运算替代。在那之后，该团队进一步提出了二值化神经网络（Binarized neural networks，BNN），其不仅会将权重变为二值，而且也会将卷积神经网络运行时的激活也设为二值。 
而在 AdderNet 中，特征往往聚集在不同的类别中心，这是因为 AdderNet 使用了 L1 距离来区别不同的类别。这个可视化结果说明 L1 距离和传统的互相关都可被用作度量，来计算深度神经网络中滤波器与输入特征之间距离的相似度。由于减法可使用加法的补码轻松实现，因此仅使用加法的 L1 度量可作为一种对硬件友好的度量，并且在构建神经网络时可以很自然地有效替代卷积。 
该研究的初步结果已在 CVPR 2020 发表（arXiv:1912.13200）。本文要介绍的是最新的研究成果，在新版本中，AdderNet 的性能已经获得了显著的提升，并且还具有了完善的理论保证。  
在图像分类任务上，AdderNet 的表现与 CNN 相近，且几乎不需要任何乘法计算，在精度上优于二值化神经网络（BNN，不过 BNN 的模型要小得多）。在常用的 ResNet-18 和 ResNet-50 架构上，AdderNet 新版本的精度已经和原始卷积网络十分相似，差距在一个点以内。  


## 开源项目


> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [microsoft/SuperBench：Hardware and Software Benchmarks for AI Systems]()  
项目：https://microsoft.github.io/superbenchmark/
摘要：SuperBench is a validation and profiling tool for AI infrastructure. It provides micro-benchmark for primitive computation and communication benchmarking, as well as model-benchmark to measure domain-aware end-to-end deep learning workloads. SuperBench supports:
    - AI infrastructure validation and diagnosis
        - Distributed validation tools to validate hundreds or thousands of servers automatically
        - Consider both raw hardware and E2E model performance with ML workload patterns
        - Build a contract to identify hardware issues
        - Provide infrastructural-oriented criteria as Performance/Quality Gates for hardware and system release
        - Provide detailed performance report and advanced analysis tool
    - AI workload benchmarking and profiling
        - Provide comprehensive performance comparison between different existing hardware
        - Provide insights for hardware and software co-design

## 博文


- [『豪门盛宴』AI训练芯片和系统最新战况 | StarryHeavensAbove](https://mp.weixin.qq.com/s/jVEY3PFeFymyKCL0oz6D8A)  
摘要：MLPerf的工作已经持续了几年，Training的Benchmark是最早开展工作，也是到目前为止最受瞩目的工作。不出意料的话，各个厂商都会“宣称”自己夺得了“xxx的冠军”。0.7版本的结果出来之后，Nvidia做了一个对比图，试图做归一化的比较，但也很难说是非常合理的对比。我之前对这个问题的比喻是“关公战秦琼”，这也是MLPerf基准测试面临的困难之一。
那么，如果结果很难对比的话，组织和参与这样的“竞赛”的意义是什么呢？  
第一，这符合“AI训练军备竞赛”的需要。只要在AI上“大力出奇迹”的规律不变，AI模型的规模就会越来越大。  
第二，有利于提升芯片厂商的综合能力。如前面MLPerf的简单介绍，它测试的是软硬件系统的综合能力。如果我们观察华为ResNet的数据，0.7版本使用Tensoflow框架，这次使用的是Mindspore。  
第三，Benchmark的设计和讨论本身也可以促进相关技术的进步。设计一个好的Benchmark也是高技术工作，需要对算法和系统软硬件的技术趋势和实现有深入的理解。  


