---
layout: default
---

# 嵌入式AI简报 (2021-05-21)  

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本次17条。【新闻】；【论文】；【开源】；【博文】。


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 联发科：推出了内置 AI 处理器 MediaTek APU的 Kompanio 系列平台，高度整合的 SoC 设计、提升能效的前沿技术，平台，可为各种基于语音和视觉的 AI 应用提供算力。

据介绍，凭借高性能、低功耗的特点，以及在 5G 网络连接与 AI 方面的优势， Kompanio 系列平台为 Chromebook 笔记本电脑、平板电脑以及更多形态的个人设备带来计算能力，满足用户移动计算的使用需求。
- 手机市场：realme副总裁徐起：上半年 5G 高端芯片严重缺货如骁龙 888/870，4G 芯片缺货更严重。下半年涨价趋势是必然的，存储和芯片、甚至充电器元器件都在涨，涨价幅度大概在 10% 左右；
- Github：仓库的Issues (议题)、Pull requests （拉取请求）和Discussions （讨论）等，可以上传视频，支持的视频格式包括：.mp4和.mov两种文件；
- 美国 && 超算：全球球最快AI超算Perlmutter上线，近 4 百亿亿次浮点运算的 AI 性能，包括6159个A100 Tensor Core GPU。将在美国国家能源研究科学计算中心 (NERSC) 正式投入使用，是迄今人工智能领域使用 16 位和 32 位混合精度数学处理工作负载的最快超级计算机；
- 谷歌：Pixel 6的Whitechapel处理器的新细节再曝光，可能将是一款性能与Snapdragon 870相似的5nm芯片，据传谷歌会将重点放在机器学习技术上使其AI性能达到其它领先的移动芯片的水平；
- 商汤：计划最快年底前赴港上市，同时推动在A股上市。据悉，商汤科技最近已就来港上市与内部及外部人士进行了讨论。该公司对在香港及上海两地上市持开放态度，但目前未知会否两地同时上市；
- 英特尔：7纳米处理器完成Tape in，台积电或协助生产。英特尔新任CEO帕特·基尔辛格（Pat Gelsinger） 日前宣布，7 纳米制程的Meteor Lake 处理器计算模组已完成处理器设计。7 纳米制程Meteor Lake 处理器将为新一代Core-i 系列处理器导入重大设计变更，也就是以类似小芯片的方式藉由多个计算模组（Compute Tile）组成，并采用取代Golden Cove 的全新Redwood Cove 核心架构，预计可带来IPC 性能和架构方面的重大改进，将接替10 纳米制程Alder Lake 和RaptorLake 处理器；
- 苹果：M1曝出违反ARM机构规范的无法修复漏洞，苹果承认存在该问题。开发人员Hector Martin 近期发现，搭载于新款iPad Pro/MacBook Air/MacBook Pro/Mac mini/重新设计过的iMac 的M1 芯片竟然有无法修复的安全漏洞，可让两个应用程序秘密交换数据，即便使用者没有开启使用应用程序，一样可数据交换。不仅仅M1，iPhone 12采用的A14 芯片也有一样问题；该漏洞也可能存在下一代M1 芯片（M1X）；

> 注：个别链接打不开，请点击文末【阅读原文】跳转


## 业界新闻  

- [谷歌I/O大会：第四代 TPU 每秒10万万亿次运算，今年将向谷歌云用户提供服务 | 量子位](https://mp.weixin.qq.com/s/3LkNDLOxKe2S5Mhj6Wq59A)  
链接：https://spectrum.ieee.org/tech-talk/computing/hardware/heres-how-googles-tpu-v4-ai-chip-stacked-up-in-training-tests  
摘要：一个TPU v4 pod就能达到1 exaflop级的算力，v4将主要以 pod 形式应用，一个 pod 由 4096 个 TPU v4 单芯片组成，可以达到1 exaflop级的算力，这相当于1000万台笔记本电脑之和。  
与上一代TPU v3相比，在64个芯片的规模下，TPU v4的性能平均提升了2.7倍。TPU v4 pod的性能较TPU v3 pod提升了10倍。在BERT的训练中，256块TPU v4也将时长缩短到1.82分钟。后续 v4 pod将会应用在谷歌的数据中心，并在今年内向谷歌云用户提供服务。  
- [台积电开始量产苹果A15芯片，iPhone 13或如期发布 | 芯东西](https://mp.weixin.qq.com/s/9PRsWaX7pCR6bROaykzWXQ)  
摘要：据台媒报道，台积电已开始量产苹果新一代iPhone芯片A15，这将为iPhone 13系列提供动力。去年，苹果的生产计划被疫情打乱节奏，iPhone 12系列的发货时间比以往晚了1个月左右。不过今年到现在为止，尽管芯片短缺、部分地区新冠肺炎疫情仍在蔓延等问题还未改善，苹果似乎正避开各种不利因素，其新一代iPhone预计最早将于今年9月发布。  
据报道，A15芯片的需求量将超过A14。A15将使用与A14相同的5nm制造工艺，也有传言称苹果将在2022年使用4nm芯片。另据业内人士透露，苹果iPhone供应链中的下游模块制造商可能会在6月左右开始为相关零部件的出货，为苹果新一代iPhone设备做准备。  
A15芯片的需求量将超过A14。A15将使用与A14相同的5nm制造工艺，也有传言称苹果将在2022年使用4nm芯片。  
- [Arm全面计算战略重磅升级！Armv9架构CPU | 芯基建](https://mp.weixin.qq.com/s/38WzCqPVvY1qIdkNJgpxGg)  
摘要：今年三月，Arm推出了面向未来十年的新一代架构Armv9。今天，Arm发布新一代CPU、GPU产品和互联技术，Arm要用全新的全面计算产品组合，应对智能手机、高性能PC、可穿戴等众多应用的计算需求和设计挑战。  
全新的CPU内核包括高性能核心Cortex-X1的升级版Cortex-X2，Cortex-A78的继任者Cortex-A710，时隔四年后升级Cortex-A55的全新小核心Cortex-A510。
三款全新的CPU核心都基于今年三月份推出的Armv9架构，可谓一键三连，因此在改进性能和效率的同时，也将拥有扩展的SVE（可伸缩矢量扩展）、机密计算架构、内存标签扩展特性。  
    1. Arm新一代Mali GPU产品包括高端系列Mali-G78的继任者Mali-G710，中端系列Mail-G57的后继产品Mali-G510，以及高能效产品Mali-G310。新款中低端G610继承了 Mali-G710 的所有功能，微体系结构相同，但价格更低。G610配置低于7个内核。Arm的高端GPU并不十分理想，三星已经确认在下一代Exynos GPU中采用AMD RDNA GPU，海思麒麟SoC被按下了暂停键。联发科成为最后一个会采用Mali高端GPU的公司，但他们至今还未推出真正的旗舰级SoC，所以有可能看不到高端Mali-G710产品。  
    2. Arm还发布了CoreLink CI-700 一致性互连技术和 CoreLink NI-700片上网络互连技术与Arm CPU、GPU和NPU IP搭配，可跨SoC解决方案增强系统性能。   
    3. 对32位的舍弃。为了了支持生态系统对于性能的需求， 2023 年将仅提供 64 位的移动应用大核和小核。因为在Armv9架构的全新三款CPU中，Cortex-X2和Cortex-A510只支持AArch64微体系结构，它们不再能够执行AArch32代码，而Cortex-A710仍将支持AArch32。Arm解释称这主要是为了满足中国市场需求，由于中国移动应用市场缺乏像Google Play商店的同类生态系统，中国的供应商以及应用程序需要更多时间过渡到64位应用程序。这意味着，在采用Arm全新Cortex内核的SoC上如果要运行32位的应用程序，只能运行在Cortex-A710核心。
    4. 新的Armv9架构的三个CPU产品的哲学。X2和A710总体保持着X1和A78的目标，**X系列愿意在合理的范围内折衷功率，通过微体系结构提高性能**。**A710则更着重于PPA（性能、功耗、面积）的平衡**，通过更智能的设计提高性能和效率。**小核A510是四年来的首次更新，是一种全新的小巧设计。**
Arm称Cortex-A510新内核与此前的旗舰内核Cortex-A73的单核性能和频率非常相似，但功耗却低很多。据悉，Arm采用了一个被称为“合并内核”的设计方法，这是一种非常复杂的方法，最多两个核心对，它们共享L2缓存系统以及它们之间的FP / NEON / SVE管道。Armv9-A CPU群集（cluster）的支柱是新款的动态共享单元（ DynamIQ Shared Unit）DSU-110，DSU-110 具备可扩展性、可支持最多八Cortex-X2 内核配置，同时确保效率表现。


## 论文


- [傅里叶变换取代Transformer自注意力层，谷歌这项研究GPU上快7倍、TPU上快2倍 | 我爱计算机视觉](https://mp.weixin.qq.com/s/1Ws8WiWwWHk5zS8_rf1JAw)  
摘要：来自谷歌的研究团队表明，将傅里叶变换取代 transformer 自监督子层，可以在 GLUE 基准测试中实现 92% 的准确率，在 GPU 上的训练时间快 7 倍，在 TPU 上的训练时间快 2 倍。 
- [技术的真相 I 让手机夜拍也精彩的原理竟然是 | 旷视研究院](https://mp.weixin.qq.com/s/CcHWpRQ_Ur9zWbSntHCBCg)  
摘要：如今的手机夜拍已经做到即使暗光拍摄都能清晰可见。其实，图像质量的变高，都离不开对相机ISP参数的调试。
AI的技术突破，给ISP发展带来了源源不断的动力，例如在清晰度提升方面，有NN降噪网络，超分网络，AI demosaic网络等。在色彩调整方面，目前也有AI AWB的方案，AI风格迁移的发展方向。
另外，AI在传统的基础CV算法方面也有很大的提升，例如在光流对齐、三维重建方面、图像检测都有很好的效果，这些都是可以和传统ISP相结合的点，从而提升ISP的图像处理能力。  
本文将带你揭秘让夜拍越来越精彩的神奇技术背后的实现细节。


## 开源项目


> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [plasma-umass/scalene: a high-performance, high-precision CPU, GPU, and memory profiler for Python](https://github.com/plasma-umass/scalene)  
摘要：Scalene 是一个 Python 的高性能 CPU, GPU 和 内存分析器，可在行级别下执行CPU分析，如代码行执行时间。
CPU分析：可将库调用和用户代码时间分开，解耦分离出系统花费时间如I/O调度时间；GPU 分析：目前仅限于基于nVidia的系统；Memory 分析：如代码行内存使用分析，识别内存泄漏，该功能是通过引用专门的内存分配器来实现的。也可以在分理出 Python代码 与 本地代码 内存消耗的百分比。此外，也支持通过 @profile 装饰器只对特定函数进行分析。当 Scalene 在对后台启动(通过 &)的程序进行分析时， 你可以 暂停和恢复分析。  
- [navervision/mlsd: 用手机就能实时给图像直线描边，速度不亚于目标检测，在线Demo可玩 | 量子位](https://mp.weixin.qq.com/s/YoNOcbMiFQRqzMezb7e2cw)  
- 网页Demo：https://gradio.app/g/AK391/mlsd  
- 文章：https://arxiv.org/abs/2106.00186  
摘要：利用LSD可以快速检测图像中的直线段，从而根据图像的几何特征设计算法，快速确定目标区域。虽然之前的线段检测模型也能做到实时性，但往往只有在计算性能不错的GPU上才能实现。为了满足这些需求，一个名为M-LSD的移动设备实时线段检测模型出现了。  
据作者表示，这是首个能在移动设备上运行的线段检测模型，目前已开源。M-LSD决定只用一个模块，直接生成center/displacement map，从而一步到位预测图像中的线段，极大地降低模型大小。事实上，这个模型也确实非常小：1~11层基于MobileNet改编，12~16层则是一个自顶向下结构。只相当于大型线段检测模型如ResNet等体积的2.5%。相比于其他大型模型（圆圈大小表示模型大小），M-LSD能在线段检测精度几乎保持不变的情况下，将模型运行速度提升至原来的2.3倍+。作者们推出了M-LSD和M-LSD-tiny两个模型，都可以在安卓和苹果机上实时运行。M-LSD-tiny最快能以56.8FPS和48.6FPS的速度在手机上实时运行。  


## 博文


- [MegEngine TensorCore 卷积算子实现原理 | 旷视研究院](https://mp.weixin.qq.com/s/4J-w61alohKg7Mm3-82rjw)  
摘要：本文将会深入介绍MegEngine CUDA平台的底层卷积算子的实现原理，并将会对Nvidia CUTLASS的Implicit GEMM卷积文档进行解读和补充，算子性能可以达到cudnn的80%以上。  
- [内联汇编很可怕吗？看完这篇文章，终结它！ | IOT物联网小镇](https://mp.weixin.qq.com/s/3LFUDmK1To9oQWhUgau1Iw)  
摘要：在 Linux 代码中，经常可以看到在 C 代码中，嵌入部分汇编代码，这些代码要么是与硬件体系相关的，要么是对性能有关键影响的。这篇文章，我们就来详细聊一聊在 C 语言中，如何通过 asm 关键字来嵌入汇编语言代码，文中的 8 个示例代码从简单到复杂，逐步深入地介绍内联汇编的关键语法规则。  
- [面向NNA 功能覆盖的精简操作集计算 （ROSC） | Imagination Tech](https://mp.weixin.qq.com/s/VJsL5RNguJH_z4gMnzlZQA)  
摘要：RISC（精简指令集计算机）的设计理念长久性地改变了计算的面貌，在本文中，我们提出了一种全新涉及神经网络加速器功能的方案：精简操作集计算（ROSC）。
从 RISC 及其演变情况来看，重点是小型、高度灵活和低层级的指令集，允许更深入的流水、向编译器的复杂性转移以及更好的整体性能。RISC 几十年来一直主导着计算机架构，是当今领先处理器架构的基础。
然而，RISC 的优势在某些操作局限于少量特定操作的应用。这种计算问题的一个典型例子是卷积神经网络（CNN） 推理，其中绝大多数的计算和带宽要求针对少量层：例如，卷积、池化和激活。在这样的设置中，需要使用硬件加速器，并针对这些常见任务进行专用的固定功能实现。执行这些操作之外的任何操作都将导致硬件无法打造最佳状态，要消耗更多的功耗和面积，以达到每秒相同的目标操作数。

