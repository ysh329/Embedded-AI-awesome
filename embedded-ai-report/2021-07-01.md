---
layout: default
---

# 嵌入式AI简报 (2021-07-01)  

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：

好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：


> 注：个别链接打不开，请点击文末【阅读原文】跳转


## 业界新闻  

- [重启自研架构，三星和高通对ARM投下“不信任票” | 三易生活](https://mp.weixin.qq.com/s/Cx6wC10nECNs9POwjvTtOA)  
摘要：三星最近正在寻求多位曾在苹果和AMD CPU团队任职的工程师加入，并且到目前为止，至少有一名曾在苹果芯片团队担任主要开发任务的工程师，已经给出了入职条件。  
其次，就在前段时间，高通刚刚完成了对CPU架构设计公司Nuvia的收购。而在Nuvia的职员当中，不少人都曾参与过苹果M1芯片的设计。据报道，Nuvia已经完成了并入高通后的首款CPU设计方案，虽然它现在似乎还是一款规模非常巨大，主要针对服务器这样的高性能计算领域，但Nuvia的架构非常新颖，以至于它不仅性能远超Intel与AMD的同级别产品，而且也有望在未来成功小型化，并用于智能手机。  
什么促使他们做出自研CPU决定的呢？  
    1. ARM在产品性能宣传方面一贯有着“吹水”的传统。特别是在每次新品发布的时候，为了凸显公版新架构的“提升很大”，ARM往往会安排新架构与老架构进行性能对比。简单换算一下就会发现，其实新架构的同频性能变化并不是那么大。
；  
    2. ARM本身的归属问题也引发了担忧。英伟达一旦收购ARM成功之后，一个横跨移动、PC、车载、高性能计算（HPC）、云计算的超级半导体巨头可能就将冉冉升起。一方面，从ARM现有的产品线来看，他们与英伟达之间在移动GPU方案的研发和授权上存在一定的竞争关系。另一方面，ARM虽然目前隶属于日本公司软银，但其总部却是在英国，而研发部门则更是有两家，分别在英国剑桥和美国奥斯汀。这就意味着对于现在的ARM来说，他们只有奥斯汀分公司的产品会受到美国相关法令的出口管制。而一旦ARM被英伟达收购，由于英伟达本身是美国公司，就会导致整个ARM产品线全部被纳入美国政府的监管范围，这很显然会让ARM的客户对于其未来的供货能力产生担忧。更进一步地说，大家知道英伟达的主要业务是设计和销售显卡芯片、自动驾驶处理器、服务器加速卡等等设备，而ARM的业务则是设计芯片，以及销售设计方案。事实上在英伟达的一些产品中，本身就会需要用到ARM的指令集和架构授权。这也就意味着一旦英伟达收购ARM，本身相对于高通、三星，以及其他的同类厂商来说，就变成了既是架构和技术供应商，又是直接竞争对手的关系。可能带来交易不公平。  
- [Jim Keller正在做的芯片，有望挑战英伟达 | 半导体行业观察](https://mp.weixin.qq.com/s/S_30W69nkegcLH66DutnLA)  
摘要：作为最重要的 AI 初创公司之一，Tenstorrent 获得了大量媒体报道。除了有前途的硬件和软件设计，媒体炒作这家公司的部分原因是因为他们由芯片行业的专家Jim Keller领导。公司成立以来，他就一直是其中的一名投资者。在特斯拉任职后，他又去英特尔工作，最终于 2021 年初，Jim Keller成为了Tenstorrent 的首席技术官。  
据报道，Tenstorrent 采用了一种将硬件和软件紧密结合的独特方法。硬件专门用于该任务，但软件并不复杂。  
整个软件栈只有大约 50,000 行代码。与大多数其他需要自定义开发pipeline的特定于 AI 的 ASIC 不同，Tenstorrent 具有很强的适应性和灵活性，同时支持所有主要工具链、框架和runtime。那就意味着，英伟达极易开发的最大优势正在受到挑战。  
- [高通推出骁龙888 Plus 5G移动平台 | 高通骁龙](https://mp.weixin.qq.com/s/kM1WQusx4IzsLTx5E0zA9A)  
摘要：高通技术公司今日宣布推出全新骁龙888 Plus 5G移动平台，即骁龙888旗舰移动平台的升级产品。升级的旗舰移动平台将为2021年下半年来自华硕、荣耀、Motorola、vivo和小米的智能手机提供支持。  
骁龙888相比，骁龙888 Plus集成的高通Kryo 680 CPU，超级内核主频高达3.0GHz*，此外，其支持的第6代高通AI引擎的算力高达每秒32万亿次运算（32 TOPS），AI性能提升超过20%。  



## 论文

- [CVPR2021][轻量化目标检测模型MobileDets | 集智书童](https://mp.weixin.qq.com/s/CoMa863Buvz_ftyXGFENUw)  
摘要：构建在深度卷积上的Inverted bottleneck layers已经成为移动设备上最先进目标检测模型的主要构建模块。在这项工作中，作者通过回顾常规卷积的实用性，研究了这种设计模式在广泛的移动加速器上的最优性。  
作者研究发现，正则卷积是一个强有力的组件，以提高延迟-准确性权衡目标检测的加速器，只要他们被放置在网络通过神经结构搜索。通过在搜索空间中合并Regular CNN并直接优化目标检测的网络架构，作者获得了一系列目标检测模型，MobileDets，并在移动加速器中实现了最先进的结果。  
在COCO检测任务上，在移动CPU上MobileDets比MobileNetV3+SSDLite提升了1.7 mAP。MobileDets比MobileNetV2+SSDLite提升了1.9mAP，在不增加延迟的情况下，在谷歌EdgeTPU上提升了3.7 mAP，在Qualcomm Hexagon DSP上提升了3.4 mAP，在Nvidia Jetson GPU上提升了2.7 mAP。此外，MobileDets即使不使用金字塔也可以在移动cpu上媲美最先进的MnasFPN，并在EdgeTPUs和dsp上实现更好的mAP分数以及高达2倍的加速。


## 开源项目


> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [Adlik/Adlik: 深度学习推理工具链 Adlik 新版本Cheetah发布](https://github.com/Adlik/Adlik)  
摘要：Adlik [ædlik] is an end-to-end optimizing framework for deep learning models. The goal of Adlik is to accelerate deep learning inference process both on cloud and embedded environment. With Adlik framework, different deep learning models can be deployed to different platforms with high performance in a much flexible and easy way.
相较于上个版本，我们做了很多优化，在MLPerf的测试中有不错的表现:
    1. 模型编译器Model Compiler
        - Adlik编译器扩展支持多种新的深度学习框架，包括PaddlePaddle，Caffe，和MxNet；
        - Adlik编译器目标模型格式，扩展支持PaddlePaddle，TVM等；
    2. 编译器支持OpenVINO量化
        - 支持TVM自动搜索，通过重新规划调度模板，采用全局自动调度搜索方案，对Resnet50模型进行优化，推理时延在X86 CPU下略优于OpenVINO（基于MLPerf测试结果）
    3. 模型优化器Model optimizer
        - Yolo v4模型优化
        - Resnet-50最新剪枝，蒸馏，量化等优化，模型大小压缩93%，精度76%，推理时延1.33ms（MLPerf测试），8核推理比原始模型提升5.0x，单核提升10.7x
    4. 推理引擎Inference Engine
        - 支持TVM TF-TRT 运行时
        - 云原生镜像发布0.3版本，支持引擎各组件最新版本：
        - OpenVINO：2021.1.110版本
        - TensorFlow：2.4.0
        - TensorRT：7.2.1.6
        - TFLite：2.4.0
        - TVM：0.7
    5. Benchmark Test
        - 支持Paddle的性能测试，包括Paddle OCR，PP-yolo，PPresnet-50
- [Tencent/TFace：更可信的人脸识别，腾讯优图TFace正式开源！| 腾讯优图AI开放平台](https://mp.weixin.qq.com/s/fd-ZSjXbfyrG8WqXGzjyAw)  
项目：https://github.com/Tencent/TFace  
摘要：TFace是由腾讯优图实验室研发的人脸识别算法研究项目，其中TFace中的T意为“trusty”，表达了团队在可信人脸识别技术方向上的愿景。
基于可信人脸识别的理念，TFace重点关注人脸识别领域的四个研究方向：精准、公平、可解释以及隐私。，框架主要由数据增强、骨干网络模型库、模型评估、训练范式等高度抽象化模块组成，通过简单的修改配置文件就可以开展相应的实验，支持多种骨干网络结构和heads, 复现了学术界主流的SOTA方法和效果，同时也利用工业界主流的推理框架测试了不同模型的推理耗时。  
    1. 在数据预增强模块中，针对困难场景下识别精度低这一难题，从2D和3D两条路线进行数据增强，目前已开放2D数据增强代码，可以扩增成戴口罩、戴眼镜、戴头巾等样本，后续TFace也会逐渐开放对于光线、表情、姿态这些细粒度属性的3D增强代码；
    2. 在骨干网络模型库中，实现了十余种学术界常见的人脸识别提特征网络结构；
    3. 模型评估模块主要包括了推理耗时评估和精度评估，测试在X86 CPU, ARM CPU, GPU具体设备上的推理速度，；
    4. 在训练范式上，支持常见的数据并行+模型并行以及混合精度训练，提升大规模训练的效率，支持多数据分支训练，采用类似多任务学习的方式同时训练多个数据集，提升模型的精度，后续将会开放量化感知训练、模型蒸馏、联邦训练等代码。  
TFace项目中的算法能力已应用在内外多个业务中，对内广泛支撑了腾讯内部如微信，QQ中的身份识别需求，对外则通过腾讯云服务的形式，提供了ToC、ToB的相关能力，典型应用案例如跨年龄寻人、人脸核身、刷脸支付等。  



## 博文

- [Wiztalk | 087期 包云岗《开源芯片：现状与趋势-RICS-V指令集》 | 腾讯高校合作](https://mp.weixin.qq.com/s/RQbEdHWV7iqjdlYquIrZbw)  
摘要：在降低芯片设计门槛上有一个关键点，那就是芯片指令集的开源。那么受到众人青睐的RSIC-V指令集又有什么过人之处呢？  
本期包云岗研究员将给我们讲讲RSIC-V指令集相较于X86、ARM指令集的优势，以及它的一些情况。  
- [知识蒸馏中的架构搜索与自监督蒸馏方法的设计 | 智东西公开课](https://apposcmf8kb5033.h5.xiaoeknow.com/v2/course/alive/l_60bf23ebe4b0017651a32bed?app_id=appoSCMf8kb5033&pro_id=p_60bf2590e4b0017651a32d0d&type=2&available=true)  
摘要：在轻量化网络加速方面，现有的模型压缩方法也不少，比如模型剪枝、设计更高效的网络结构、矩阵分解、模型量化或二值化，以及知识蒸馏等。其中知识蒸馏作为一项成熟的技术，经常被用来更好地训练小模型。而在监督学习的范式下，最近几年有很多高效的蒸馏方法被提出。而在本次的讲座中，顾金东博士将与大家探讨以下两个课题:
    1. 给定一个老师模型，如何为学生模型寻找一个好的架构，使得蒸馏效果更好？  
    2. 自监督学习最近收到了很大关注，这种学习范式已经学习的特征已经可以与监督学习下的相比较，然而自监督学习下小模型的很不好。那如何使用知识蒸馏技术来改善自监督学习下的小模型呢？  
- [Tiramisu：一种基于Polyheral的深度学习模型编译器 | Adlik](https://mp.weixin.qq.com/s/xMD83hYD3qVkzYFM_yYvQQ)  
摘要：Tiramisu是一种4层IR结构的，基于Polyhedral模型的编译器，相比基于区间分析的Halide具有更好的领域适用性。在深度学习模型、算子仍在持续发展，类似Tiramisu这样的模型编译器或许未来会成为推理引擎从业者的趁手利器。由Relay IR转化为Tensor IR的步骤称为“调度生成”，对于TVM以外的推理引擎，该步骤的名称可能有差异，但都是必须的。调度的关键在于从时间、空间两个维度上彻底挖掘计算资源的极限潜能：
    1. 时间维度上，任意时刻应尽可能地并行化数据无依赖关系的计算（CPU多物理核、GPU流处理器、CPU/GPU高级指令集），以避免不必要的串行计算；
    2. 空间维度上，尽可能将计算所需的数据放置于存取速度最快的区域（CPU L1 Cache、GPU L1 Cache、GPU C-Cache、GPU共享内存等），减少数据读写时间。  
综上可知，推理引擎的核心在于模型编译器，模型编译器的核心在于调度过程的生成技术。基于依赖分析的Polyhedral模型的调度描述更加细化、表达力更强，理论上可以将优化做到极致，但缺点是算法原理相对复杂且优化分析的复杂度更高。  
- [Tengine支持RISC-V 模型部署-全志在线D1开发板「哪吒」 | Tengine开发者社区](https://mp.weixin.qq.com/s/Hqn8Fql_YaPlm6tlRyngWg)  
摘要：全志科技在 2021年4月15日发布了“D1”处理器，是全球首颗搭载平头哥玄铁 C906 RISC-V 的应用处理器。同时由其负责开发者社区运营的全资子公司「全志在线」发布了基于D1芯片的开发板——「哪吒」。D1芯片及开发板为万物互联的 AIoT 时代提供了新的可选方案，同时也进一步扩充了 RISC-V 高端应用处理器阵营的力量。  
开放的边缘 AI 计算框架 Tengine 已经基于平头哥的 RISC-V Qemu 环境完成了 C910 的 Vector 指令的支持，由于 C910 同 C906 属于 RV64 的同一系列，指令集兼容，因此将 Tengine 移植到 D1 上只需使用 D1 的交叉编译工具完成“一键编译”即可，Tengine 已经在 v1.4 版本的编译模块中完成了微调，可无缝切换到对 D1 工具链的支持。  
