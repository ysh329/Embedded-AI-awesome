---
layout: default
---

# 嵌入式AI简报 (2021-01-19)  

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本次17条。【新闻】；【论文】；【开源】；【博文】。


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：


- 光子芯片：Nature连发两篇光子AI芯片论文，《用于光学神经网络的11 TOPS光子卷积加速器（11 TOPS photonic convolutional accelerator for optical neural networks）》、《利用积分光子张量核的并行卷积处理（Parallel convolutional processing using an integrated photonic tensor core）》；
- 高通：与长城汽车合作，后者将基于高通Ride平台打造自己的自动驾驶系统Coffee Intelligence； 
- 联发科：成为 MLCommons 创始成员携手联盟成员推动人工智能标准。MLCommons 是一个开放式 AI 创新实践产业联盟，由多家全球领导厂商发起成立（微软/facebook/alibaba/baidu等），将共同致力于推进机器学习和人工智能的标准及衡量指标；

> 注：个别链接打不开，请点击文末【阅读原文】跳转


## 业界新闻  

- [Graphcore创新社区共建：与阿里云HALO及微软亚洲研究院NNFusion | Graphcore](https://mp.weixin.qq.com/s/tJBpXRcALG24KM7MJDSsQw)  
摘要：Graphcore现已携手阿里云在GitHub上开源了专为阿里云HALO定制的代码odla_PopArt，意味着从GitHub上下载HALO可以直接在IPU上适配。Graphcore是阿里云HALO/ODLA的合作伙伴之一。早在2020年5月，阿里云就在OCP全球峰会上首次对外公布了ODLA接口标准，并[宣布已率先在Graphcore等生态伙伴上获得支持github.com/alibaba/heterogeneity-aware-lowering-and-optimization#halo](https://github.com/alibaba/heterogeneity-aware-lowering-and-optimization#halo）。  
微软亚洲研究院打造的深度神经网络编译器NNFusion使用统一的接口，让模型能够在不同的硬件厂商的芯片上无缝的运行。研究表明，在IPU上，LSTM的训练模型相比英伟达和AMD的GPU以及TPU，得到了3倍的提升。NNFusion现已在GitHub开源[github.com/microsoft/nnfusion](https://github.com/microsoft/nnfusion)。  

- [在移动设备上实现实时LiDAR 3D目标检测 | 
 
3D目标检测是一项重要任务，尤其是在自动驾驶应用领域。然而，在自动驾驶汽车的边缘计算设备上以有限的计算和内存资源来支持实时性能具有挑战性。为了实现这一目标，我们提出了一个具有编译器感知能力的统一框架，该框架将网络增强和剪枝搜索与强化学习技术结合在一起，以便能够在资源受限的边缘计算设备上实时推断3D目标检测。具体而言，使用生成器循环神经网络（RNN）来提供统一的方案，以自动进行网络增强和剪枝搜索，而无需人工和专业知识。统一方案的评估性能可以反馈给训练生成器RNN。实验结果表明，该框架首先在具有竞争优势的移动设备（三星Galaxy S20手机）上实现了实时3D目标检测
 
东北大学


## 论文



## 开源项目


- [https://github.com/margaretmz/awesome-tensorflow-lite]()  
摘要：有很多例子。  

- [https://github.com/ml-gde/e2e-tflite-tutorials](https://github.com/ml-gde/e2e-tflite-tutorials)  
摘要：这个repo也可以参考一下。也欢迎大家分享看到的新例子



- [VainF/Torch-Pruning: A pytorch pruning toolkit for structured neural network pruning and layer dependency maintaining.](https://github.com/VainF/Torch-Pruning)  
摘要：This tool will automatically detect and handle layer dependencies (channel consistency) during pruning. It is able to handle various network architectures such as DenseNet, ResNet, and Inception. See examples/test_models.py for more supported models.  
- [sovrasov/flops-counter.pytorch: Flops counter for convolutional networks in pytorch framework](https://github.com/sovrasov/flops-counter.pytorch)  
摘要：This script is designed to compute the theoretical amount of multiply-add operations in convolutional neural networks. It also can compute the number of parameters and print per-layer computational cost of a given network.  
Supported layers: Conv1d/2d/3d (including grouping), ConvTranspose1d/2d/3d (including grouping), BatchNorm1d/2d/3d, Activations (ReLU, PReLU, ELU, ReLU6, LeakyReLU), Linear, Upsample
Poolings (AvgPool1d/2d/3d, MaxPool1d/2d/3d and adaptive ones).  
Experimental support: RNN, LSTM, GRU (NLH layout is assumed), RNNCell, LSTMCell, GRUCell.  
- [tencent-ailab/pika: a lightweight speech processing toolkit based on Pytorch and (Py)Kaldi](https://github.com/tencent-ailab/pika)  
摘要：PIKA is a lightweight speech processing toolkit based on Pytorch and (Py)Kaldi. The first release focuses on end-to-end speech recognition. We use Pytorch as deep learning engine, Kaldi for data formatting and feature extraction.  
Key Features: 1. On-the-fly data augmentation and feature extraction loader; 2. TDNN Transformer encoder and convolution and transformer based decoder model structure; 3. RNNT training and batch decoding; 4. RNNT decoding with external Ngram FSTs (on-the-fly rescoring, aka, shallow fusion); 5. RNNT Minimum Bayes Risk (MBR) training; 6. LAS forward and backward rescorer for RNNT; 7. Efficient BMUF (Block model update filtering) based distributed training.  

## 博文

- [Paddle Serving全新设计Pipeline Serving！带来更高吞吐量、更高GPU利用率 | 飞桨PaddlePaddle](https://mp.weixin.qq.com/s/ccTiNqcz62n3ANwc_ZLEZg)  
摘要：Paddle Serving是飞桨服务化部署框架，其0.4.0版本有如下三点核心升级：  
    1. 支持Pipeline Serving全异步设计的推理服务部署框架，实验证明，OCR任务的吞吐量提升1.5倍，GPU利用率提升1倍；  
    2. 支持NVIDIA TensorRT高性能推理库，实现模型推理低延迟、高吞吐；  
    3. 支持多系统、多语言客户端，覆盖更多的部署场景；  
